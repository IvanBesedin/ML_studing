# README: Анализ и прогнозирование ожирения на основе поведенческих факторов

## 1. Выбор датасета

**Датасет:** ObesityDataSet_raw_and_data_sinthetic.csv

**Почему выбран этот датасет:**
Хотелось больше практики с классификацией и работой с категориальными признаками

**Целевая переменная:** NObeyesdad – категория веса (7 классов: от недостаточного веса до ожирения III типа).

---

## 2. Гипотезы до начала работы

Перед началом анализа были выдвинуты следующие гипотезы:

1. **Гипотеза 1:** Признак `CALC` со значением `Always` не влияет на качество модели и может быть удален так как это только одна запись.
2. **Гипотеза 2:** Объединение категорий `Automobile` и `Public_Transportation` в одну группу не ухудшит качество модели.
3. **Гипотеза 3:** Удаление категорий `Motorbike`, `Bike` не приведет к значительному падению точности.
4. **Гипотеза 4:** Для прогнозирования достаточно использовать только рост (`Height`) и вес (`Weight`) – остальные признаки избыточны.
5. **Гипотеза 5:** Многоклассовая логистическая регрессия (Softmax) покажет лучший результат, чем деревья решений и случайный лес.

---

## 3. Анализ данных и подготовка (Preprocessing)

### 3.1. Первичный анализ
- Пропуски в датасете отсутствуют.
- Числовые признаки: Age, Height, Weight, FCVC, NCP, CH2O, FAF, TUE.
- Категориальные признаки: Gender, CALC, FAVC, SCC, SMOKE, family_history_with_overweight, CAEC, MTRANS, NObeyesdad.

### 3.2. Предобработка данных
1. **Бинаризация бинарных признаков:**
   - `Gender`: Female → 0, Male → 1
   - `FAVC`, `SCC`, `SMOKE`, `family_history_with_overweight`: no → 0, yes → 1

2. **Кодирование порядковых признаков:**
   - `CALC` и `CAEC` преобразованы в числовые шкалы:
     - no → 0
     - Sometimes → 1
     - Frequently → 2
     - Always → 3

3. **One-hot encoding транспорта (MTRANS):**
   - Созданы бинарные признаки для `Automobile`, `Public_Transportation`, `Walking`, `Motorbike`, `Bike`.

4. **Удаление редких категорий (гипотеза 3):**
   - Удалены признаки `MTRANS_Motorbike` и `MTRANS_Bike`.

5. **Удаление единичного наблюдения (гипотеза 1):**
   - Удалена строка с `CALC == 3` (Always) – всего 1 запись.

6. **Визуализация данных:**
   - Построены гистограммы распределений признаков и матрица корреляций.
   - Обнаружена корреляция между `Weight` и целевой переменной, а также между `Height` и `Weight` (мультиколлинеарность).

7. **Масштабирование:**
   - Применён `StandardScaler` для всех признаков.

---

## 4. Подтверждение гипотез

### **Гипотеза 1 – Подтвердилась**
- Удаление единственной записи с `CALC = Always` не повлияло на метрики модели (accuracy осталась ~0.86). Признак был практически пустым и неинформативным.

### **Гипотеза 2 – Подтвердилась**
- Объединение `Automobile` и `Public_Transportation` не ухудшило качество модели. Accuracy осталась на уровне 0.8649, F1-macro даже немного вырос.

### **Гипотеза 3 – Не подтвердилась**
- Удаление `Motorbike` и `Bike` не только не ухудшило, но и немного улучшило F1-macro (с 0.8572 до 0.8577). Модель стала более устойчивой без редких категорий.

### **Гипотеза 4 – Подтвердилась частично**
- Использование только `Weight` и `Height` дало **лучший результат** среди всех экспериментов с логистической регрессией без подбора гиперпараметров:
  - Accuracy: **0.9028**
  - F1-macro: **0.9016**
- Это подтверждает, что большинство информации содержится именно в этих двух признаках.

### **Гипотеза 5 – Подтвердилась**
- Логистическая регрессия без подбора гиперпараметров показала хороший результат (0.9028), **Random Forest** с глубиной 13 (подобранный параметр) дал более высокие метрики:
  - Accuracy: **0.9597**
  - F1-macro: **0.9593**
- Дерево решений с глубиной 10 показало результат ниже (0.9384).
- Однако Логистическая регрессия с подбором гиперпараметров, а именно solver = `lbfgs` penalty = `l2`, С = `339.322`.
Дает:  
  - Accuracy на test: **0.9692**
  - F1-macro на test: **0.9685**


---

## 5. Сравнение моделей

| Модель                     | Признаки           | Accuracy | F1-macro |
|----------------------------|--------------------|----------|----------|
| Softmax LogReg             | Все (без Always)   | 0.8649   | 0.8577   |
| Softmax LogReg             | Только рост + вес  | **0.9028** | **0.9016** |
| Softmax LogReg с гиперпараметрами  | Все                |  **0.9692**   | **0.9685**   |
| Decision Tree (depth 10)   | Все                | 0.9384   | 0.9367   |
| Random Forest (depth 13)   | Все                | **0.9597** | **0.9593** |

**Лучшая модель:** Softmax LogReg с гиперпараметрами 
- **Параметры:** olver = `lbfgs` penalty = `l2`, С = `339.322`.
- **Признаки:** все (кроме редких и `CALC Always`)  
- **Результат:** Accuracy 0.9692, F1-macro 0.9685

LogisticRegresion показал наилучшую способность к обобщению, минимальное переобучение и высокую стабильность на тестовой выборке.

---
## 6. Cравненеи моделей с их выбранными параметрами

С использованием метода RFECV каждая модель выбрала свои лучшие признаки
- DecisionTreeClassifier ['Age', 'Gender', 'Height', 'Weight']
- RandomForestClassifier ['Age', 'Height', 'Weight', 'FCVC']
- LogisticRegression ['Gender', 'Height', 'Weight', 'FCVC']

Итоговые результаты с использованием только лучших признаков

|Model                         |train F1 mean  |train F1 std  |Test F1|     
|------------------------------|--------------|---------|------|                                                  
|LogisticRegression            |0.9618        |0.0125   |0.9735|
|RandomForestClassifier        |0.9561        |0.0093   |0.9534|
|DecisionTreeClassifier        |0.9495        |0.0078   |0.9496|

Как видно Логистическая регрессия ведет себя еще лучше, а вот Дерево решений и Случайный лес стали вести себя хуже. Видимо это из-за того, что удаленные классы несли довольно важдную информацию для разбиения. А для Логистической регрессии удаленные параметры были лишними и вносили больше шума чем пользы

## 7. Итоговый вывод

- Наибольший вклад в предсказание вносят признаки **Weight** и **Height**.
- Логистическая регрессия на двух признаках даёт высокий результат и является хорошей базовой моделью.
- Удаление редких и неинформативных категорий улучшает качество и ускоряет обучение.
- Гипотеза о бесполезности `CALC Always` и редких видов транспорта подтвердилась.
- Гипотеза о превосходстве логистической регрессии над деревьями **Подтвердилась**.
